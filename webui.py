import io
import base64
import time
import requests
import numpy as np
import streamlit as st

# WebRTCë¡œ ë§ˆì´í¬ ë…¹ìŒ
import av
from scipy.io.wavfile import write
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase

st.set_page_config(page_title="í†µí•© STTâ†’ì •ì±…ê²€ìƒ‰â†’TTS", layout="centered")
st.title("ìŒì„± ë³µì§€ì •ì±… ë„ìš°ë¯¸ (í†µí•© ì„œë²„ í…ŒìŠ¤íŠ¸ UI)")

# -----------------------------
# ì‚¬ì´ë“œë°”: ì„œë²„/ì˜µì…˜
# -----------------------------
st.sidebar.header("ì„œë²„ & ì˜µì…˜")
# ë°°í¬ëœ ì„œë²„ ì£¼ì†Œë¡œ ê¸°ë³¸ê°’ ì„¤ì •
API_BASE = st.sidebar.text_input("API Base URL", "http://165.132.46.88:32374") 
ENGINE = st.sidebar.selectbox("STT ì—”ì§„", ["fw", "ow"], index=0)
LANG = st.sidebar.text_input("ì–¸ì–´", "ko")
VOICE = st.sidebar.selectbox("TTS ìŒì„±", ["ko-KR-SunHiNeural", "ko-KR-InJoonNeural"], index=0)
TOPK = st.sidebar.number_input("ê²€ìƒ‰ TopK", min_value=1, max_value=10, value=3)
BEAM = st.sidebar.number_input("Faster-Whisper beam_size", min_value=1, max_value=10, value=5)
TIMEOUT = st.sidebar.number_input("ìš”ì²­ íƒ€ì„ì•„ì›ƒ(sec)", min_value=5, max_value=300, value=120)

# STT, ê²€ìƒ‰, TTS í†µí•© íŒŒì´í”„ë¼ì¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
PIPELINE_URL = f"{API_BASE}/stt_search_tts"
HEALTHZ_URL = f"{API_BASE}/healthz"

st.caption("TIP: ë°±ì—”ë“œ ì„œë²„ëŠ” `http://165.132.46.88:32374`ì— **/stt_search_tts** ì—”ë“œí¬ì¸íŠ¸ê°€ ë°°í¬ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

# -----------------------------
# WebRTC ì˜¤ë””ì˜¤ ìˆ˜ì§‘ (ë§ˆì´í¬)
# -----------------------------
class AudioProcessor(AudioProcessorBase):
    def __init__(self) -> None:
        self.buffers = []
        self.sr = 48000
    def recv_audio(self, frame: av.AudioFrame) -> av.AudioFrame:
        self.buffers.append(frame.to_ndarray())
        return frame

def save_wav_from_buffers(buffers, sr=48000, path="tmp_input.wav"):
    if not buffers:
        return None
    data = np.concatenate(buffers, axis=1)
    if data.ndim == 2 and data.shape[0] > 1:
        data = data.mean(axis=0, keepdims=True)  # stereo -> mono
    data = (data.squeeze() * 32767).astype("int16")
    write(path, sr, data)
    return path

tabs = st.tabs(["ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ", "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ"])

# ìƒíƒœ ì €ì¥
if "last_json" not in st.session_state:
    st.session_state.last_json = None

# -----------------------------
# íƒ­ 1: ë§ˆì´í¬ ë…¹ìŒ
# -----------------------------
with tabs[0]:
    st.subheader("ğŸ™ï¸ ë§ˆì´í¬ â†’ /stt_search_tts")
    st.markdown("1) **Start** ëˆŒëŸ¬ ë§í•˜ê³  â†’ 2) **ğŸ§ í˜„ì¬ ë…¹ìŒë¶„ ì „ì†¡**")

    ctx = webrtc_streamer(
        key="stt-pipeline",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=1024,
        media_stream_constraints={"audio": True, "video": False},
        async_processing=False,
        audio_processor_factory=AudioProcessor,
    )

    c1, c2 = st.columns(2)
    with c1:
        if ctx and ctx.state.playing and st.button("ğŸ§ í˜„ì¬ ë…¹ìŒë¶„ ì „ì†¡"):
            try:
                if ctx.audio_processor:
                    path = save_wav_from_buffers(ctx.audio_processor.buffers, sr=48000)
                    if not path:
                        st.warning("ìˆ˜ì§‘ëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ë…¹ìŒ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    else:
                        with open(path, "rb") as f:
                            files = {"audio": ("input.wav", f, "audio/wav")}
                            data = {
                                "engine": ENGINE,
                                "language": LANG,
                                "beam_size": int(BEAM),
                                "topk": int(TOPK),
                                "voice": VOICE,
                            }
                            st.spinner("ì„œë²„ì— ìš”ì²­ ì¤‘...")
                            t0 = time.time()
                            res = requests.post(PIPELINE_URL, files=files, data=data, timeout=TIMEOUT)
                            dt = time.time() - t0
                        if res.ok:
                            st.session_state.last_json = res.json()
                            st.success(f"ì„±ê³µ! (RTT {dt:.2f}s)")
                        else:
                            st.error(f"ì˜¤ë¥˜: {res.status_code} {res.text}")
                else:
                    st.error("ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

    with c2:
        if st.button("ğŸ§ª ì„œë²„ ìƒíƒœ ì²´í¬(/healthz)"):
            try:
                hres = requests.get(HEALTHZ_URL, timeout=10)
                st.write(hres.json() if hres.ok else hres.text)
            except Exception as e:
                st.error(f"healthz ì‹¤íŒ¨: {e}")

# -----------------------------
# íƒ­ 2: íŒŒì¼ ì—…ë¡œë“œ
# -----------------------------
with tabs[1]:
    st.subheader("ğŸ“ íŒŒì¼ â†’ /stt_search_tts")
    up = st.file_uploader("ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ (wav/mp3/m4a ë“±)", type=["wav", "mp3", "m4a"])
    if up and st.button("ğŸš€ ì—…ë¡œë“œ íŒŒì¼ë¡œ ìš”ì²­ ë³´ë‚´ê¸°"):
        try:
            audio_bytes = up.read()
            files = {"audio": (up.name, audio_bytes, up.type)}
            data = {
                "engine": ENGINE,
                "language": LANG,
                "beam_size": int(BEAM),
                "topk": int(TOPK),
                "voice": VOICE,
            }
            st.spinner("ì„œë²„ì— ìš”ì²­ ì¤‘...")
            t0 = time.time()
            res = requests.post(PIPELINE_URL, files=files, data=data, timeout=TIMEOUT)
            dt = time.time() - t0
            if res.ok:
                st.session_state.last_json = res.json()
                st.success(f"ì„±ê³µ! (RTT {dt:.2f}s)")
            else:
                st.error(f"ì˜¤ë¥˜: {res.status_code} {res.text}")
        except Exception as e:
            st.error(f"ìš”ì²­ ì‹¤íŒ¨: {e}")

# -----------------------------
# ê²°ê³¼ í‘œì‹œ/ì¬ìƒ
# -----------------------------
st.divider()
st.subheader("ê²°ê³¼")

if st.session_state.last_json:
    js = st.session_state.last_json

    # STT ê²°ê³¼
    st.markdown("### ğŸ“ STT ê²°ê³¼")
    st.write(js.get("stt", {}))

    # ê²€ìƒ‰ ê²°ê³¼
    st.markdown("### ğŸ” ê²€ìƒ‰ ê²°ê³¼")
    # ì„œë²„ ì‘ë‹µ êµ¬ì¡°: js['search']['results']
    results = js.get("search", {}).get("results", []) 
    if results:
        cols = st.columns(3)
        for i, item in enumerate(results):
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•„ìš”í•œ í•„ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            service_name = item.get('service_name') or item.get('ì„œë¹„ìŠ¤ëª…', 'N/A')
            support_content = item.get('support') or item.get('ì§€ì›ë‚´ìš©', 'N/A')
            tags = item.get('tags', 'N/A')
            
            # íƒœê·¸ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¼ ê²½ìš° ë³´ê¸° ì¢‹ê²Œ ë³€í™˜
            if isinstance(tags, list):
                tags_text = ", ".join(t.strip("['\"") for t in tags)
            else:
                tags_text = tags.strip("['\"")

            with cols[i % 3]:
                # ì„œë¹„ìŠ¤ëª…ê³¼ ë­í¬ë¥¼ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
                title_text = f"{i+1}. {service_name}"
                with st.expander(f"**{title_text}**", expanded=True):
                    # ì§€ì›ë‚´ìš©ê³¼ íƒœê·¸ê°€ ì„±ê³µì ìœ¼ë¡œ í‘œì‹œë¨
                    st.markdown(f"**ì§€ì›ë‚´ìš©:** {support_content}")
                    st.markdown(f"**íƒœê·¸:** {tags_text}")
    else:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # í•©ì„± ìŒì„±
    st.markdown("### ğŸ”Š í•©ì„± ìŒì„± (TTS)")
    tts = js.get("tts", {})
    b64 = tts.get("audio_mp3_b64")
    
    # TTS ê²°ê³¼ì—ì„œ 'spoken_text' í•„ë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ì½ì–´ì¤„ ë¬¸ì¥ í™•ì¸
    spoken_text = tts.get("spoken_text") or js.get("summary", "ì½ì–´ì¤„ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

    if b64:
        # Base64 ë°ì´í„°ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ì¬ìƒ ì‹œë„
        try:
            st.audio(base64.b64decode(b64), format="audio/mp3")
        except Exception as e:
            st.error(f"ì˜¤ë””ì˜¤ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
    else:
        # ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ê°€ ë¹„ì–´ìˆì„ ê²½ìš°, ì„œë²„ ì¸¡ TTS ì˜¤ë¥˜ë¥¼ ì˜ì‹¬
        st.error("ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì„œë²„ì—ì„œ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì„œë²„ ì¸¡ TTS ì˜¤ë¥˜ ê°€ëŠ¥ì„±)")

    with st.expander("ì½ì–´ì¤€ ë¬¸ì¥ í™•ì¸"):
        # spoken_text í•„ë“œë¥¼ ì¶œë ¥
        st.write(spoken_text)
else:
    st.info("ì•„ì§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ íƒ­ì—ì„œ ë§ˆì´í¬ ë…¹ìŒ ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ í›„ ì „ì†¡í•˜ì„¸ìš”.")
