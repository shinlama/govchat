import io
import base64
import time
import requests
import numpy as np
import streamlit as st
from openai import OpenAI

# WebRTCë¡œ ë§ˆì´í¬ ë…¹ìŒ
import av
from scipy.io.wavfile import write
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase

st.set_page_config(page_title="í†µí•© STTâ†’ì •ì±…ê²€ìƒ‰â†’TTS", layout="centered")
st.title("ìŒì„± ë³µì§€ì •ì±… ë„ìš°ë¯¸ (í†µí•© ì„œë²„ í…ŒìŠ¤íŠ¸ UI)")

# -----------------------------
# ì‚¬ì´ë“œë°”: ì„œë²„/ì˜µì…˜
# -----------------------------
st.sidebar.header("ì„œë²„ & ì˜µì…˜")
# ë°°í¬ëœ ì„œë²„ ì£¼ì†Œë¡œ ê¸°ë³¸ê°’ ì„¤ì •
API_BASE = st.sidebar.text_input("API Base URL", "http://165.132.46.88:31180") 
ENGINE = st.sidebar.selectbox("STT ì—”ì§„", ["fw", "ow"], index=0)
LANG = st.sidebar.text_input("ì–¸ì–´", "ko")
VOICE = st.sidebar.selectbox("TTS ìŒì„±", ["ko-KR-SunHiNeural", "ko-KR-InJoonNeural"], index=0)
TOPK = st.sidebar.number_input("ê²€ìƒ‰ TopK", min_value=1, max_value=10, value=3)
BEAM = st.sidebar.number_input("Faster-Whisper beam_size", min_value=1, max_value=10, value=5)
TIMEOUT = st.sidebar.number_input("ìš”ì²­ íƒ€ì„ì•„ì›ƒ(sec)", min_value=5, max_value=300, value=120)

# OpenAI API Key ì„¤ì •
OPENAI_API_KEY = st.sidebar.text_input("OpenAI API Key", type="password")

# STT, ê²€ìƒ‰, TTS í†µí•© íŒŒì´í”„ë¼ì¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
PIPELINE_URL = f"{API_BASE}/stt_search_tts"
HEALTHZ_URL = f"{API_BASE}/healthz"

st.caption("TIP: ë°±ì—”ë“œ ì„œë²„ëŠ” `http://165.132.46.88:31180`ì— **/stt_search_tts** ì—”ë“œí¬ì¸íŠ¸ê°€ ë°°í¬ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

# -----------------------------
# OpenAIë¥¼ ì‚¬ìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„± í•¨ìˆ˜
# -----------------------------
def generate_policy_summary(service_data):
    """ì •ì±… ì •ë³´ë¥¼ í•µì‹¬ ìš”ì•½ìœ¼ë¡œ ë³€í™˜"""
    if not OPENAI_API_KEY:
        return None
    
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        prompt = f"""
ë‹¤ìŒ ì •ì±… ì •ë³´ë¥¼ í•µì‹¬ ë‚´ìš©ë§Œ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”:

ì„œë¹„ìŠ¤ëª…: {service_data.get('service_name', 'N/A')}
ì§€ì›ë‚´ìš©: {service_data.get('support', 'N/A')}
ì‹ ì²­ëŒ€ìƒ: {service_data.get('target_beneficiaries', 'N/A')}
ì‹ ì²­ê¸°ê°„: {service_data.get('application_deadline', 'N/A')}
ì‹ ì²­ë°©ë²•: {service_data.get('application_method', 'N/A')}
ë¬¸ì˜ì²˜: {service_data.get('contact', 'N/A')}
í•„ìš”ì„œë¥˜: {service_data.get('required_documents', 'N/A')}

ìš”êµ¬ì‚¬í•­:
1. ì–´ë–¤ ì •ì±…ì¸ì§€ (ì§€ì›ë‚´ìš©)
2. ì‹ ì²­ ëŒ€ìƒ
3. ì‹ ì²­ ê¸°ê°„
4. ì‹ ì²­ ë°©ë²•
5. í•„ìš”í•œ ì„œë¥˜
6. ë¬¸ì˜ì²˜
ì´ 6ê°€ì§€ í•µì‹¬ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì„œ ì„¤ëª…

í•µì‹¬ ìš”ì•½:
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ë¶€ ì •ì±…ì˜ í•µì‹¬ ì •ë³´ë¥¼ ëª…í™•í•˜ê²Œ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300,
            temperature=0.5
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"ì •ì±… ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def generate_field_summary(service_data, field_name):
    """íŠ¹ì • í•„ë“œì˜ ë‚´ìš©ì„ ìš”ì•½"""
    if not OPENAI_API_KEY:
        return None
    
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        field_value = service_data.get(field_name, 'N/A')
        if field_value == 'N/A' or not field_value:
            return None
        
        field_labels = {
            'support': 'ì§€ì›ë‚´ìš©',
            'target_beneficiaries': 'ì‹ ì²­ëŒ€ìƒ',
            'application_deadline': 'ì‹ ì²­ê¸°ê°„',
            'application_method': 'ì‹ ì²­ë°©ë²•',
            'required_documents': 'í•„ìš”ì„œë¥˜',
            'contact': 'ë¬¸ì˜ì²˜'
        }
        
        field_label = field_labels.get(field_name, field_name)
        
        prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{field_value}

ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬
2. ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
3. ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì œê±°
4. í•œêµ­ì–´ë¡œ ì‘ì„±

ìš”ì•½:
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ {field_label} ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            temperature=0.3
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        return None

def generate_tts_summary(service_data):
    """TTSìš© 4ì¤„ ìš”ì•½ ìƒì„±"""
    if not OPENAI_API_KEY:
        return None
    
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        prompt = f"""
ë‹¤ìŒ ì •ì±… ì •ë³´ë¥¼ 4ì¤„ ì´ë‚´ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ì„œë¹„ìŠ¤ëª…: {service_data.get('service_name', 'N/A')}
ì§€ì›ë‚´ìš©: {service_data.get('support', 'N/A')}
ì‹ ì²­ëŒ€ìƒ: {service_data.get('target_beneficiaries', 'N/A')}
ì‹ ì²­ë°©ë²•: {service_data.get('application_method', 'N/A')}
í•„ìš”ì„œë¥˜: {service_data.get('required_documents', 'N/A')}
ë¬¸ì˜ì²˜: {service_data.get('contact', 'N/A')}

ìš”êµ¬ì‚¬í•­:
1. "ì¶”ì²œí•˜ëŠ” ì •ì±…ì€ [ì •ì±…ëª…]ì…ë‹ˆë‹¤."ë¡œ ì‹œì‘
2. "ëŒ€ìƒì€ [ì‹ ì²­ëŒ€ìƒ]ì´ë©°"ë¡œ ì´ì–´ì§
3. "ì‹ ì²­ ë°©ë²•ì€ [ì‹ ì²­ë°©ë²•]ì´ê³ "ë¡œ ì´ì–´ì§
4. "ì–´ë– í•œ ì„œë¥˜ë¥¼ í†µí•´ ì–´ë–»ê²Œ ì‹ ì²­í•˜ë©´ ë©ë‹ˆë‹¤. ë¬¸ì˜ì²˜ëŠ” [ë¬¸ì˜ì²˜]ì…ë‹ˆë‹¤."ë¡œ ë§ˆë¬´ë¦¬
5. 4ì¤„ ì´ë‚´ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
6. ìŒì„±ìœ¼ë¡œ ì½ê¸° ì¢‹ê²Œ ì‘ì„±

ìš”ì•½:
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ì±… ì •ë³´ë¥¼ ìŒì„±ìœ¼ë¡œ ì½ê¸° ì¢‹ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.7
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        return None

def display_policy_info(service_data, index):
    """ì •ì±… ì •ë³´ë¥¼ Streamlit UI ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ"""
    service_name = service_data.get('service_name', 'N/A')
    
    # ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
    with st.container():
        st.markdown(f"### {index+1}. {service_name}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“‹ ì§€ì›ë‚´ìš©**")
            if OPENAI_API_KEY:
                with st.spinner("ì§€ì›ë‚´ìš© ìš”ì•½ ì¤‘..."):
                    support_summary = generate_field_summary(service_data, 'support')
                    st.write(support_summary if support_summary else service_data.get('support', 'N/A'))
            else:
                st.write(service_data.get('support', 'N/A'))
            
            st.markdown("**ğŸ‘¥ ì‹ ì²­ëŒ€ìƒ**")
            if OPENAI_API_KEY:
                with st.spinner("ì‹ ì²­ëŒ€ìƒ ìš”ì•½ ì¤‘..."):
                    target_summary = generate_field_summary(service_data, 'target_beneficiaries')
                    st.write(target_summary if target_summary else service_data.get('target_beneficiaries', 'N/A'))
            else:
                st.write(service_data.get('target_beneficiaries', 'N/A'))
            
            st.markdown("**ğŸ“… ì‹ ì²­ê¸°ê°„**")
            if OPENAI_API_KEY:
                with st.spinner("ì‹ ì²­ê¸°ê°„ ìš”ì•½ ì¤‘..."):
                    deadline_summary = generate_field_summary(service_data, 'application_deadline')
                    st.write(deadline_summary if deadline_summary else service_data.get('application_deadline', 'N/A'))
            else:
                st.write(service_data.get('application_deadline', 'N/A'))
        
        with col2:
            st.markdown("**ğŸ“ ì‹ ì²­ë°©ë²•**")
            if OPENAI_API_KEY:
                with st.spinner("ì‹ ì²­ë°©ë²• ìš”ì•½ ì¤‘..."):
                    method_summary = generate_field_summary(service_data, 'application_method')
                    st.write(method_summary if method_summary else service_data.get('application_method', 'N/A'))
            else:
                st.write(service_data.get('application_method', 'N/A'))
            
            st.markdown("**ğŸ“„ í•„ìš”ì„œë¥˜**")
            if OPENAI_API_KEY:
                with st.spinner("í•„ìš”ì„œë¥˜ ìš”ì•½ ì¤‘..."):
                    docs_summary = generate_field_summary(service_data, 'required_documents')
                    st.write(docs_summary if docs_summary else service_data.get('required_documents', 'N/A'))
            else:
                st.write(service_data.get('required_documents', 'N/A'))
            
            st.markdown("**ğŸ“ ë¬¸ì˜ì²˜**")
            if OPENAI_API_KEY:
                with st.spinner("ë¬¸ì˜ì²˜ ìš”ì•½ ì¤‘..."):
                    contact_summary = generate_field_summary(service_data, 'contact')
                    st.write(contact_summary if contact_summary else service_data.get('contact', 'N/A'))
            else:
                st.write(service_data.get('contact', 'N/A'))
        
        st.markdown("---")

# -----------------------------
# WebRTC ì˜¤ë””ì˜¤ ìˆ˜ì§‘ (ë§ˆì´í¬)
# -----------------------------
class AudioProcessor(AudioProcessorBase):
    def __init__(self) -> None:
        self.buffers = []
        self.sr = 48000
    def recv_audio(self, frame: av.AudioFrame) -> av.AudioFrame:
        self.buffers.append(frame.to_ndarray())
        return frame

def save_wav_from_buffers(buffers, sr=48000, path="tmp_input.wav"):
    if not buffers:
        st.write("ğŸ” ë””ë²„ê¹…: buffersê°€ None ë˜ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
        return None
    
    try:
        st.write(f"ğŸ” ë””ë²„ê¹…: buffers ê¸¸ì´ = {len(buffers)}")
        data = np.concatenate(buffers, axis=1)
        st.write(f"ğŸ” ë””ë²„ê¹…: concatenated data shape = {data.shape}")
        
        if data.ndim == 2 and data.shape[0] > 1:
            data = data.mean(axis=0, keepdims=True)  # stereo -> mono
            st.write(f"ğŸ” ë””ë²„ê¹…: mono ë³€í™˜ í›„ shape = {data.shape}")
        
        data = (data.squeeze() * 32767).astype("int16")
        st.write(f"ğŸ” ë””ë²„ê¹…: ìµœì¢… data shape = {data.shape}, dtype = {data.dtype}")
        
        write(path, sr, data)
        st.write(f"ğŸ” ë””ë²„ê¹…: íŒŒì¼ ì €ì¥ ì™„ë£Œ - {path}")
        return path
    except Exception as e:
        st.error(f"ğŸ” ë””ë²„ê¹…: ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ - {e}")
        return None

tabs = st.tabs(["ğŸ™ï¸ ë§ˆì´í¬ ë…¹ìŒ", "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ"])

# ìƒíƒœ ì €ì¥
if "last_json" not in st.session_state:
    st.session_state.last_json = None

# -----------------------------
# íƒ­ 1: ë§ˆì´í¬ ë…¹ìŒ
# -----------------------------
with tabs[0]:
    st.subheader("ğŸ™ï¸ ë§ˆì´í¬ â†’ /stt_search_tts")
    st.markdown("1) **Start** ëˆŒëŸ¬ ë§í•˜ê³  â†’ 2) **ğŸ§ í˜„ì¬ ë…¹ìŒë¶„ ì „ì†¡**")

    ctx = webrtc_streamer(
        key="stt-pipeline",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=1024,
        media_stream_constraints={"audio": True, "video": False},
        async_processing=False,
        audio_processor_factory=AudioProcessor,
    )

    c1, c2 = st.columns(2)
    with c1:
        if ctx and ctx.state.playing and st.button("ğŸ§ í˜„ì¬ ë…¹ìŒë¶„ ì „ì†¡"):
            try:
                if ctx.audio_processor:
                    # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                    buffer_count = len(ctx.audio_processor.buffers) if ctx.audio_processor.buffers else 0
                    st.write(f"ğŸ” ë””ë²„ê¹…: ë²„í¼ ê°œìˆ˜ = {buffer_count}")
                    
                    if buffer_count == 0:
                        st.warning("âš ï¸ ì˜¤ë””ì˜¤ ë²„í¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ë…¹ìŒí•´ì£¼ì„¸ìš”.")
                    else:
                        path = save_wav_from_buffers(ctx.audio_processor.buffers, sr=48000)
                        if not path:
                            st.warning("ìˆ˜ì§‘ëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ë…¹ìŒ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        else:
                            st.success(f"âœ… ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì™„ë£Œ: {path}")
                            
                        with open(path, "rb") as f:
                            files = {"audio": ("input.wav", f, "audio/wav")}
                            data = {
                                "engine": ENGINE,
                                "language": LANG,
                                "beam_size": int(BEAM),
                                "topk": int(TOPK),
                                "voice": VOICE,
                            }
                            
                            # 1ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ë°›ê¸°
                            st.spinner("ì„œë²„ì— ìš”ì²­ ì¤‘...")
                            t0 = time.time()
                            res = requests.post(PIPELINE_URL, files=files, data=data, timeout=TIMEOUT)
                            dt = time.time() - t0
                            
                            # 2ë‹¨ê³„: GPT ìš”ì•½ ìƒì„± í›„ TTS ìš”ì²­
                            if res.ok and OPENAI_API_KEY:
                                search_results = res.json().get("search", {}).get("results", [])
                                if search_results:
                                    with st.spinner("GPT ìš”ì•½ ìƒì„± ì¤‘..."):
                                        tts_summary = generate_tts_summary(search_results[0])
                                        if tts_summary:
                                            # GPT ìš”ì•½ í…ìŠ¤íŠ¸ë¡œ TTS ìš”ì²­
                                            data["tts_text"] = tts_summary
                                            st.spinner("GPT ìš”ì•½ìœ¼ë¡œ ìŒì„± ìƒì„± ì¤‘...")
                                            t0 = time.time()
                                            res = requests.post(PIPELINE_URL, files=files, data=data, timeout=TIMEOUT)
                                            dt = time.time() - t0
                        if res.ok:
                            st.session_state.last_json = res.json()
                            st.success(f"ì„±ê³µ! (RTT {dt:.2f}s)")
                        else:
                            st.error(f"ì˜¤ë¥˜: {res.status_code} {res.text}")
                else:
                    st.error("ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

    with c2:
        if st.button("ğŸ§ª ì„œë²„ ìƒíƒœ ì²´í¬(/healthz)"):
            try:
                hres = requests.get(HEALTHZ_URL, timeout=10)
                st.write(hres.json() if hres.ok else hres.text)
            except Exception as e:
                st.error(f"healthz ì‹¤íŒ¨: {e}")

# -----------------------------
# íƒ­ 2: íŒŒì¼ ì—…ë¡œë“œ
# -----------------------------
with tabs[1]:
    st.subheader("ğŸ“ íŒŒì¼ â†’ /stt_search_tts")
    up = st.file_uploader("ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ (wav/mp3/m4a ë“±)", type=["wav", "mp3", "m4a"])
    if up and st.button("ğŸš€ ì—…ë¡œë“œ íŒŒì¼ë¡œ ìš”ì²­ ë³´ë‚´ê¸°"):
        try:
            audio_bytes = up.read()
            files = {"audio": (up.name, audio_bytes, up.type)}
            data = {
                "engine": ENGINE,
                "language": LANG,
                "beam_size": int(BEAM),
                "topk": int(TOPK),
                "voice": VOICE,
            }
            
            st.spinner("ì„œë²„ì— ìš”ì²­ ì¤‘...")
            t0 = time.time()
            res = requests.post(PIPELINE_URL, files=files, data=data, timeout=TIMEOUT)
            dt = time.time() - t0
                
            if res.ok:
                st.session_state.last_json = res.json()
                st.success(f"ì„±ê³µ! (RTT {dt:.2f}s)")
            else:
                st.error(f"ì˜¤ë¥˜: {res.status_code} {res.text}")
        except Exception as e:
            st.error(f"ìš”ì²­ ì‹¤íŒ¨: {e}")

# -----------------------------
# ê²°ê³¼ í‘œì‹œ/ì¬ìƒ
# -----------------------------
st.divider()
st.subheader("ê²°ê³¼")

if st.session_state.last_json:
    js = st.session_state.last_json

    # STT ê²°ê³¼
    st.markdown("### ğŸ“ STT ê²°ê³¼")
    st.write(js.get("stt", {}))

    # ê²€ìƒ‰ ê²°ê³¼
    st.markdown("### ğŸ” ê²€ìƒ‰ ê²°ê³¼")
    # ì„œë²„ ì‘ë‹µ êµ¬ì¡°: js['search']['results'] 
    results = js.get("search", {}).get("results", []) 
    if results:
        for i, item in enumerate(results):
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•„ìš”í•œ í•„ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            service_name = item.get('service_name') or item.get('ì„œë¹„ìŠ¤ëª…', 'N/A')
            support_content = item.get('support') or item.get('ì§€ì›ë‚´ìš©', 'N/A')
            target_beneficiaries = item.get('target_beneficiaries', 'N/A')
            application_deadline = item.get('application_deadline', 'N/A')
            application_method = item.get('application_method', 'N/A')
            contact = item.get('contact', 'N/A')
            required_documents = item.get('required_documents', 'N/A')

            # ìƒˆë¡œìš´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ì±… ì •ë³´ í‘œì‹œ
            display_policy_info(item, i)
    else:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # í•©ì„± ìŒì„±
    st.markdown("### ğŸ”Š í•©ì„± ìŒì„± (TTS)")
    tts = js.get("tts", {})
    # ì„œë²„ë³„ í‚¤ í˜¸í™˜: audio_mp3_b64 ë˜ëŠ” mp3_b64
    b64 = tts.get("audio_mp3_b64") or tts.get("mp3_b64")

    # GPT APIë¡œ 4ì¤„ ìš”ì•½ ìƒì„±
    if results and OPENAI_API_KEY:
        with st.spinner("ìŒì„±ìš© ì •ì±… ìš”ì•½ ìƒì„± ì¤‘..."):
            tts_summary = generate_tts_summary(results[0])  # ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©
            spoken_text = tts_summary if tts_summary else tts.get("spoken_text") or js.get("summary", "ì½ì–´ì¤„ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        spoken_text = tts.get("spoken_text") or js.get("summary", "ì½ì–´ì¤„ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

    def safe_b64_decode(s: str) -> bytes:
        if not isinstance(s, str):
            raise ValueError("base64 ë¬¸ìì—´ì´ ì•„ë‹˜")
        clean = s.strip().replace("\n", "").replace("\r", "")
        # ê³µë°±ì´ '+'ë¡œ ì˜ë ¤ì˜¨ ê²½ìš° ë³´ì •
        clean = clean.replace(" ", "+")
        # íŒ¨ë”© ë³´ì •
        pad = (-len(clean)) % 4
        if pad:
            clean += "=" * pad
        return base64.b64decode(clean)

    if b64:
        try:
            audio_bytes = safe_b64_decode(b64)
            st.audio(audio_bytes, format="audio/mp3")
        except Exception as e:
            st.error(f"ì˜¤ë””ì˜¤ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
    else:
        st.error("ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì„œë²„ì—ì„œ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì„œë²„ ì¸¡ TTS í‚¤(audio_mp3_b64/mp3_b64) í™•ì¸ í•„ìš”)")

    with st.expander("ì½ì–´ì¤€ ë¬¸ì¥ í™•ì¸"):
        # spoken_text í•„ë“œë¥¼ ì¶œë ¥
        st.write(spoken_text)
else:
    st.info("ì•„ì§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ íƒ­ì—ì„œ ë§ˆì´í¬ ë…¹ìŒ ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ í›„ ì „ì†¡í•˜ì„¸ìš”.")
